"""
GPUå¯¾å¿œãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
CuPyã‚’ä½¿ç”¨ã—ã¦GPUã§é«˜é€Ÿã«è¨ˆç®—
"""

import numpy as np
import pandas as pd
from typing import List, Dict, Optional, Union
from datetime import datetime

# GPU/CPUåˆ‡ã‚Šæ›¿ãˆ
try:
    import cupy as cp
    GPU_AVAILABLE = cp.cuda.is_available()
except ImportError:
    GPU_AVAILABLE = False
    cp = None


class PatternMatcher:
    """GPUå¯¾å¿œãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ£ãƒ¼"""
    
    def __init__(
        self,
        window_size: int = 20,
        lookahead: int = 10,
        top_n: int = 15,
        min_similarity: float = 0.7,
        method: str = 'correlation',
        use_gpu: bool = True,
        normalize_method: str = 'minmax'
    ):
        """
        Args:
            window_size: ãƒ‘ã‚¿ãƒ¼ãƒ³ã®é•·ã•ï¼ˆæ—¥æ•°ï¼‰
            lookahead: å°†æ¥äºˆæ¸¬ã®æœŸé–“ï¼ˆæ—¥æ•°ï¼‰
            top_n: è¿”ã™ä¸Šä½ãƒãƒƒãƒæ•°
            min_similarity: æœ€å°é¡ä¼¼åº¦
            method: é¡ä¼¼åº¦è¨ˆç®—æ–¹æ³• ('correlation', 'euclidean', 'weighted')
            use_gpu: GPUä½¿ç”¨ãƒ•ãƒ©ã‚°
            normalize_method: æ­£è¦åŒ–æ–¹æ³• ('minmax', 'zscore', 'robust')
        """
        self.window_size = window_size
        self.lookahead = lookahead
        self.top_n = top_n
        self.min_similarity = min_similarity
        self.method = method
        self.normalize_method = normalize_method
        
        # GPUä½¿ç”¨ã®æ±ºå®š
        self.use_gpu = use_gpu and GPU_AVAILABLE
        self.xp = cp if self.use_gpu else np
        
        if use_gpu and not GPU_AVAILABLE:
            print("âš ï¸  GPU requested but not available. Using CPU instead.")
        elif self.use_gpu:
            print(f"âœ… Using GPU: {cp.cuda.Device().name}")
        else:
            print("ğŸ“Š Using CPU")
    
    def normalize_pattern(self, pattern: np.ndarray) -> np.ndarray:
        """
        ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ­£è¦åŒ–
        
        Args:
            pattern: æ­£è¦åŒ–ã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³
            
        Returns:
            æ­£è¦åŒ–ã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³
        """
        if self.normalize_method == 'minmax':
            # Min-Maxæ­£è¦åŒ– [0, 1]
            min_val = pattern.min(axis=0, keepdims=True)
            max_val = pattern.max(axis=0, keepdims=True)
            return (pattern - min_val) / (max_val - min_val + 1e-8)
        
        elif self.normalize_method == 'zscore':
            # Z-scoreæ­£è¦åŒ–
            mean = pattern.mean(axis=0, keepdims=True)
            std = pattern.std(axis=0, keepdims=True)
            return (pattern - mean) / (std + 1e-8)
        
        elif self.normalize_method == 'robust':
            # Robustæ­£è¦åŒ–ï¼ˆä¸­å¤®å€¤ã¨IQRï¼‰
            median = np.median(pattern, axis=0, keepdims=True)
            q75, q25 = np.percentile(pattern, [75, 25], axis=0, keepdims=True)
            iqr = q75 - q25
            return (pattern - median) / (iqr + 1e-8)
        
        return pattern
    
    def calculate_similarity(
        self, 
        pattern1: np.ndarray, 
        pattern2: np.ndarray
    ) -> float:
        """
        2ã¤ã®ãƒ‘ã‚¿ãƒ¼ãƒ³é–“ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—
        
        Args:
            pattern1: ãƒ‘ã‚¿ãƒ¼ãƒ³1
            pattern2: ãƒ‘ã‚¿ãƒ¼ãƒ³2
            
        Returns:
            é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢
        """
        if self.use_gpu:
            pattern1_gpu = self.xp.array(pattern1)
            pattern2_gpu = self.xp.array(pattern2)
            
            if self.method == 'correlation':
                # ç›¸é–¢ä¿‚æ•°
                corr = self._correlation_gpu(pattern1_gpu, pattern2_gpu)
                return float(corr.get())
            
            elif self.method == 'euclidean':
                # ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ï¼ˆé¡ä¼¼åº¦ã«å¤‰æ›ï¼‰
                dist = self.xp.linalg.norm(pattern1_gpu - pattern2_gpu)
                similarity = 1 / (1 + float(dist.get()))
                return similarity
            
            elif self.method == 'weighted':
                # åŠ é‡é¡ä¼¼åº¦ï¼ˆæœ€è¿‘ã®ãƒ‡ãƒ¼ã‚¿ã«é‡ã¿ï¼‰
                weights = self.xp.linspace(0.5, 1.0, len(pattern1))
                weighted_diff = self.xp.sum(weights[:, None] * (pattern1_gpu - pattern2_gpu) ** 2)
                similarity = 1 / (1 + float(weighted_diff.get()))
                return similarity
        
        else:
            # CPUå®Ÿè£…
            if self.method == 'correlation':
                corr_matrix = np.corrcoef(pattern1.flatten(), pattern2.flatten())
                return corr_matrix[0, 1]
            
            elif self.method == 'euclidean':
                dist = np.linalg.norm(pattern1 - pattern2)
                return 1 / (1 + dist)
            
            elif self.method == 'weighted':
                weights = np.linspace(0.5, 1.0, len(pattern1))
                weighted_diff = np.sum(weights[:, None] * (pattern1 - pattern2) ** 2)
                return 1 / (1 + weighted_diff)
        
        return 0.0
    
    def _correlation_gpu(self, x: 'cp.ndarray', y: 'cp.ndarray') -> 'cp.ndarray':
        """GPUä¸Šã§ç›¸é–¢ä¿‚æ•°ã‚’è¨ˆç®—"""
        x_flat = x.flatten()
        y_flat = y.flatten()
        
        # å¹³å‡ã‚’å¼•ã
        x_centered = x_flat - self.xp.mean(x_flat)
        y_centered = y_flat - self.xp.mean(y_flat)
        
        # ç›¸é–¢ä¿‚æ•°
        numerator = self.xp.sum(x_centered * y_centered)
        denominator = self.xp.sqrt(self.xp.sum(x_centered ** 2) * self.xp.sum(y_centered ** 2))
        
        return numerator / (denominator + 1e-8)
    
    def find_similar_patterns(
        self,
        data: pd.DataFrame,
        target_pattern: np.ndarray,
        symbol: str = None
    ) -> List[Dict]:
        """
        é¡ä¼¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
        
        Args:
            data: æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã®DataFrame
            target_pattern: æ¤œç´¢ã™ã‚‹ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³
            symbol: éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            
        Returns:
            ãƒãƒƒãƒçµæœã®ãƒªã‚¹ãƒˆ
        """
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ­£è¦åŒ–
        target_normalized = self.normalize_pattern(target_pattern)
        
        results = []
        ohlc_cols = ['open', 'high', 'low', 'close']
        
        # ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º
        for i in range(len(data) - self.window_size - self.lookahead + 1):
            window_data = data.iloc[i:i + self.window_size][ohlc_cols].values
            
            # æ­£è¦åŒ–
            window_normalized = self.normalize_pattern(window_data)
            
            # é¡ä¼¼åº¦è¨ˆç®—
            similarity = self.calculate_similarity(target_normalized, window_normalized)
            
            if similarity >= self.min_similarity:
                # å°†æ¥ã®ãƒªã‚¿ãƒ¼ãƒ³ã‚’è¨ˆç®—
                future_data = data.iloc[i + self.window_size:i + self.window_size + self.lookahead]
                
                if len(future_data) > 0:
                    start_price = data.iloc[i + self.window_size - 1]['close']
                    end_price = future_data['close'].iloc[-1]
                    future_return = (end_price - start_price) / start_price
                else:
                    future_return = None
                
                results.append({
                    'symbol': symbol if symbol else data['symbol'].iloc[0],
                    'similarity': similarity,
                    'start_date': data.index[i].strftime('%Y-%m-%d'),
                    'end_date': data.index[i + self.window_size - 1].strftime('%Y-%m-%d'),
                    'start_price': float(data.iloc[i]['close']),
                    'end_price': float(data.iloc[i + self.window_size - 1]['close']),
                    'future_return': float(future_return) if future_return is not None else None,
                    'match_index': i
                })
        
        # é¡ä¼¼åº¦ã§ã‚½ãƒ¼ãƒˆ
        results.sort(key=lambda x: x['similarity'], reverse=True)
        
        return results[:self.top_n]
    
    def analyze_all_symbols(
        self,
        symbols_data: Dict[str, pd.DataFrame],
        progress_callback: Optional[callable] = None
    ) -> pd.DataFrame:
        """
        å…¨éŠ˜æŸ„ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°åˆ†æ
        
        Args:
            symbols_data: éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ã®è¾æ›¸
            progress_callback: é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
            
        Returns:
            çµæœã®DataFrame
        """
        all_results = []
        total_symbols = len(symbols_data)
        
        print(f"ğŸ” Analyzing {total_symbols} symbols...")
        
        for idx, (symbol, df) in enumerate(symbols_data.items(), 1):
            try:
                # ãƒ‡ãƒ¼ã‚¿ãŒååˆ†ã«ã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                if len(df) < self.window_size + self.lookahead:
                    continue
                
                # æœ€æ–°ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º
                target_pattern = df.iloc[-self.window_size:][['open', 'high', 'low', 'close']].values
                
                # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
                results = self.find_similar_patterns(df, target_pattern, symbol)
                all_results.extend(results)
                
                # é€²æ—è¡¨ç¤º
                if progress_callback:
                    progress_callback(idx, total_symbols, symbol)
                elif idx % 10 == 0:
                    print(f"  Progress: {idx}/{total_symbols} ({idx/total_symbols*100:.1f}%)")
                
            except Exception as e:
                print(f"âš ï¸  Error processing {symbol}: {e}")
                continue
        
        if all_results:
            results_df = pd.DataFrame(all_results)
            results_df = results_df.sort_values('similarity', ascending=False)
            print(f"âœ… Found {len(results_df)} pattern matches")
            return results_df
        else:
            print("âŒ No pattern matches found")
            return pd.DataFrame()
    
    def get_stats(self) -> Dict:
        """åˆ†æçµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        return {
            'window_size': self.window_size,
            'lookahead': self.lookahead,
            'top_n': self.top_n,
            'min_similarity': self.min_similarity,
            'method': self.method,
            'use_gpu': self.use_gpu,
            'gpu_available': GPU_AVAILABLE,
            'normalize_method': self.normalize_method
        }
